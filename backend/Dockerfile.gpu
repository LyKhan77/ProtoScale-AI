# GPU Dockerfile for AI workers
FROM pytorch/pytorch:2.1.0-cuda12.1-cudnn8-runtime

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    git \
    libgl1-mesa-glx \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements first for caching
COPY requirements.txt .

# Install Python dependencies
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Create storage directories
RUN mkdir -p storage/uploads storage/jobs storage/exports

# Set environment variables
ENV PYTHONUNBUFFERED=1
ENV GPU_DEVICE=cuda

CMD ["celery", "-A", "app.tasks", "worker", "-Q", "gpu", "--concurrency=1", "--loglevel=info"]
